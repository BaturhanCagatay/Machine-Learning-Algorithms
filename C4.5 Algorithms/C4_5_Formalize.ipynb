{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Çalışır Hali"
      ],
      "metadata": {
        "id": "iyefglKIdKnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from graphviz import Digraph"
      ],
      "metadata": {
        "id": "zLV0nZdJdMRE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(data, target_col):\n",
        "    \"\"\"\n",
        "    Calculate entropy of the target column\n",
        "    \"\"\"\n",
        "    values = data[target_col].value_counts(normalize=True)\n",
        "    entropy = -sum(values * np.log2(values))\n",
        "    return round(entropy, 3)"
      ],
      "metadata": {
        "id": "LWBLlmPtdNjU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_information_gain_ratio(data, feature_col, target_col):\n",
        "    \"\"\"\n",
        "    Calculate information gain ratio of a feature\n",
        "    \"\"\"\n",
        "    total_entropy = calculate_entropy(data, target_col)\n",
        "    values = data[feature_col].unique()\n",
        "    weighted_entropy = 0\n",
        "\n",
        "    for value in values:\n",
        "        subset = data[data[feature_col] == value]\n",
        "        weight = len(subset) / len(data)\n",
        "        subset_entropy = calculate_entropy(subset, target_col)\n",
        "        weighted_entropy += weight * subset_entropy\n",
        "\n",
        "    info_gain = total_entropy - weighted_entropy\n",
        "\n",
        "    # Calculate Split Information\n",
        "    split_info = -sum(\n",
        "        (len(data[data[feature_col] == value]) / len(data)) * math.log2(len(data[data[feature_col] == value]) / len(data))\n",
        "        for value in values\n",
        "        if len(data[data[feature_col] == value]) > 0\n",
        "    )\n",
        "\n",
        "    # Avoid division by zero\n",
        "    gain_ratio = info_gain / split_info if split_info != 0 else 0\n",
        "    return round(gain_ratio, 3)"
      ],
      "metadata": {
        "id": "X9yLfP3TdQwZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_continuous_values(data, feature_col):\n",
        "    \"\"\"\n",
        "    Convert continuous values into categorical (e.g., below threshold, above threshold)\n",
        "    \"\"\"\n",
        "    threshold = data[feature_col].median()\n",
        "    data[feature_col] = data[feature_col].apply(lambda x: f\"below {threshold}\" if x <= threshold else f\"above {threshold}\")"
      ],
      "metadata": {
        "id": "0gxVpeAodRtC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_decision_tree(data, target_col, features, depth=0):\n",
        "    \"\"\"\n",
        "    Recursively build a decision tree using C4.5 algorithm\n",
        "    \"\"\"\n",
        "    # Check if the dataset is homogeneous\n",
        "    if len(data[target_col].unique()) == 1:\n",
        "        return data[target_col].iloc[0]\n",
        "\n",
        "    # If no features left, return the most common class\n",
        "    if not features:\n",
        "        return data[target_col].mode()[0]\n",
        "\n",
        "    # Calculate information gain ratio for each feature\n",
        "    gains = {feature: calculate_information_gain_ratio(data, feature, target_col) for feature in features}\n",
        "    best_feature = max(gains, key=gains.get)  # Choose the feature with the highest information gain ratio\n",
        "\n",
        "    # Build the decision tree\n",
        "    tree = {best_feature: {}}\n",
        "\n",
        "    for value in data[best_feature].unique():\n",
        "        subset = data[data[best_feature] == value]\n",
        "        if subset.empty:\n",
        "            tree[best_feature][value] = data[target_col].mode()[0]\n",
        "        else:\n",
        "            subtree = build_decision_tree(\n",
        "                subset,\n",
        "                target_col,\n",
        "                [feat for feat in features if feat != best_feature],\n",
        "                depth + 1\n",
        "            )\n",
        "            tree[best_feature][value] = subtree\n",
        "\n",
        "    return tree"
      ],
      "metadata": {
        "id": "Oxim5qjudVha"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rules(tree, path=\"\"):\n",
        "    \"\"\"\n",
        "    Convert a decision tree into rules\n",
        "    \"\"\"\n",
        "    if not isinstance(tree, dict):  # Leaf node\n",
        "        print(f\"{path} => {tree}\")\n",
        "        return\n",
        "\n",
        "    for node, branches in tree.items():\n",
        "        for value, subtree in branches.items():\n",
        "            new_path = f\"{path} {node} = {value}\" if path else f\"{node} = {value}\"\n",
        "            print_rules(subtree, new_path)\n"
      ],
      "metadata": {
        "id": "8mXhvjL9dXny"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_tree(tree, graph=None, parent=None, edge_label=\"\"):\n",
        "    \"\"\"\n",
        "    Visualize a decision tree using Graphviz\n",
        "    \"\"\"\n",
        "    if graph is None:\n",
        "        graph = Digraph(format='png')\n",
        "        graph.attr('node', shape='ellipse')\n",
        "\n",
        "    if isinstance(tree, dict):  # Decision node\n",
        "        for node, branches in tree.items():\n",
        "            graph.node(node, label=node)  # Add decision node\n",
        "            if parent:\n",
        "                graph.edge(parent, node, label=edge_label)\n",
        "            for branch_value, subtree in branches.items():\n",
        "                visualize_tree(subtree, graph, parent=node, edge_label=str(branch_value))\n",
        "    else:  # Leaf node\n",
        "        leaf_label = f\"{tree}\"  # Use leaf value as label\n",
        "        leaf_node = f\"{parent}_{leaf_label}\"  # Unique ID for leaf\n",
        "        graph.node(leaf_node, label=leaf_label, shape='box')\n",
        "        graph.edge(parent, leaf_node, label=edge_label)\n",
        "\n",
        "    return graph"
      ],
      "metadata": {
        "id": "og_Duu2gda4p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "file_path = input(\"Enter the path to your CSV file: \")\n",
        "target_col = input(\"Enter the target column name: \")\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APkLzl4wdc_K",
        "outputId": "1e5ee7d4-8a25-4adf-dd71-c8a7891ef461"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path to your CSV file: /content/C4.5_Dataseti1.csv\n",
            "Enter the target column name: Decision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in data.columns:\n",
        "    if feature != target_col and data[feature].dtype in ['float64', 'int64']:\n",
        "        preprocess_continuous_values(data, feature)\n",
        "\n",
        "# Define features (exclude target column)\n",
        "features = [col for col in data.columns if col != target_col]\n",
        "\n",
        "# Build the decision tree\n",
        "decision_tree = build_decision_tree(data, target_col, features)\n",
        "\n",
        "# Visualize the decision tree\n",
        "dot = visualize_tree(decision_tree)\n",
        "file_name = input(\"Enter the file name to save the tree (without extension): \")\n",
        "dot.render(file_name)  # Save the tree to a file\n",
        "print(f\"Decision tree has been saved as {file_name}.png\")\n",
        "print(\"Decision Tree Rules:\")\n",
        "print_rules(decision_tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQFpLFi_dpYq",
        "outputId": "66232dc1-072d-4343-ba07-39700d64a98b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the file name to save the tree (without extension): Dataseti1\n",
            "Decision tree has been saved as Dataseti1.png\n",
            "Decision Tree Rules:\n",
            "Outlook = Sunny Humidity = above 80.0 => No\n",
            "Outlook = Sunny Humidity = below 80.0 => Yes\n",
            "Outlook = Overcast => Yes\n",
            "Outlook = Rain Wind = Weak => Yes\n",
            "Outlook = Rain Wind = Strong => No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Hali"
      ],
      "metadata": {
        "id": "yysFDJXtdH4I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyZIhTLJdDGG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from graphviz import Digraph\n",
        "\n",
        "def calculate_entropy(data, target_col):\n",
        "    \"\"\"\n",
        "    Calculate entropy of the target column\n",
        "    \"\"\"\n",
        "    values = data[target_col].value_counts(normalize=True)\n",
        "    entropy = -sum(values * np.log2(values))\n",
        "    return round(entropy, 3)\n",
        "\n",
        "def calculate_information_gain_ratio(data, feature_col, target_col):\n",
        "    \"\"\"\n",
        "    Calculate information gain ratio of a feature\n",
        "    \"\"\"\n",
        "    total_entropy = calculate_entropy(data, target_col)\n",
        "    values = data[feature_col].unique()\n",
        "    weighted_entropy = 0\n",
        "\n",
        "    for value in values:\n",
        "        subset = data[data[feature_col] == value]\n",
        "        weight = len(subset) / len(data)\n",
        "        subset_entropy = calculate_entropy(subset, target_col)\n",
        "        weighted_entropy += weight * subset_entropy\n",
        "\n",
        "    info_gain = total_entropy - weighted_entropy\n",
        "\n",
        "    # Calculate Split Information\n",
        "    split_info = -sum(\n",
        "        (len(data[data[feature_col] == value]) / len(data)) * math.log2(len(data[data[feature_col] == value]) / len(data))\n",
        "        for value in values\n",
        "        if len(data[data[feature_col] == value]) > 0\n",
        "    )\n",
        "\n",
        "    # Avoid division by zero\n",
        "    gain_ratio = info_gain / split_info if split_info != 0 else 0\n",
        "    return round(gain_ratio, 3)\n",
        "\n",
        "def preprocess_continuous_values(data, feature_col):\n",
        "    \"\"\"\n",
        "    Convert continuous values into categorical (e.g., below threshold, above threshold)\n",
        "    \"\"\"\n",
        "    threshold = data[feature_col].median()\n",
        "    data[feature_col] = data[feature_col].apply(lambda x: f\"below {threshold}\" if x <= threshold else f\"above {threshold}\")\n",
        "\n",
        "def build_decision_tree(data, target_col, features, depth=0):\n",
        "    \"\"\"\n",
        "    Recursively build a decision tree using C4.5 algorithm\n",
        "    \"\"\"\n",
        "    # Check if the dataset is homogeneous\n",
        "    if len(data[target_col].unique()) == 1:\n",
        "        return data[target_col].iloc[0]\n",
        "\n",
        "    # If no features left, return the most common class\n",
        "    if not features:\n",
        "        return data[target_col].mode()[0]\n",
        "\n",
        "    # Calculate information gain ratio for each feature\n",
        "    gains = {feature: calculate_information_gain_ratio(data, feature, target_col) for feature in features}\n",
        "    best_feature = max(gains, key=gains.get)  # Choose the feature with the highest information gain ratio\n",
        "\n",
        "    # Build the decision tree\n",
        "    tree = {best_feature: {}}\n",
        "\n",
        "    for value in data[best_feature].unique():\n",
        "        subset = data[data[best_feature] == value]\n",
        "        if subset.empty:\n",
        "            tree[best_feature][value] = data[target_col].mode()[0]\n",
        "        else:\n",
        "            subtree = build_decision_tree(\n",
        "                subset,\n",
        "                target_col,\n",
        "                [feat for feat in features if feat != best_feature],\n",
        "                depth + 1\n",
        "            )\n",
        "            tree[best_feature][value] = subtree\n",
        "\n",
        "    return tree\n",
        "\n",
        "def print_rules(tree, path=\"\"):\n",
        "    \"\"\"\n",
        "    Convert a decision tree into rules\n",
        "    \"\"\"\n",
        "    if not isinstance(tree, dict):  # Leaf node\n",
        "        print(f\"{path} => {tree}\")\n",
        "        return\n",
        "\n",
        "    for node, branches in tree.items():\n",
        "        for value, subtree in branches.items():\n",
        "            new_path = f\"{path} {node} = {value}\" if path else f\"{node} = {value}\"\n",
        "            print_rules(subtree, new_path)\n",
        "\n",
        "def visualize_tree(tree, graph=None, parent=None, edge_label=\"\"):\n",
        "    \"\"\"\n",
        "    Visualize a decision tree using Graphviz\n",
        "    \"\"\"\n",
        "    if graph is None:\n",
        "        graph = Digraph(format='png')\n",
        "        graph.attr('node', shape='ellipse')\n",
        "\n",
        "    if isinstance(tree, dict):  # Decision node\n",
        "        for node, branches in tree.items():\n",
        "            graph.node(node, label=node)  # Add decision node\n",
        "            if parent:\n",
        "                graph.edge(parent, node, label=edge_label)\n",
        "            for branch_value, subtree in branches.items():\n",
        "                visualize_tree(subtree, graph, parent=node, edge_label=str(branch_value))\n",
        "    else:  # Leaf node\n",
        "        leaf_label = f\"{tree}\"  # Use leaf value as label\n",
        "        leaf_node = f\"{parent}_{leaf_label}\"  # Unique ID for leaf\n",
        "        graph.node(leaf_node, label=leaf_label, shape='box')\n",
        "        graph.edge(parent, leaf_node, label=edge_label)\n",
        "\n",
        "    return graph\n",
        "\n",
        "# Load dataset\n",
        "file_path = input(\"Enter the path to your CSV file: \")\n",
        "target_col = input(\"Enter the target column name: \")\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess dataset (convert continuous features to categorical)\n",
        "for feature in data.columns:\n",
        "    if feature != target_col and data[feature].dtype in ['float64', 'int64']:\n",
        "        preprocess_continuous_values(data, feature)\n",
        "\n",
        "# Define features (exclude target column)\n",
        "features = [col for col in data.columns if col != target_col]\n",
        "\n",
        "# Build the decision tree\n",
        "decision_tree = build_decision_tree(data, target_col, features)\n",
        "\n",
        "# Visualize the decision tree\n",
        "dot = visualize_tree(decision_tree)\n",
        "dot.render(\"decision_tree_c45\")  # Save the tree to a file\n",
        "print(\"Decision tree has been saved as decision_tree_c45.png\")\n",
        "print(\"Decision Tree Rules:\")\n",
        "print_rules(decision_tree)"
      ]
    }
  ]
}