{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from graphviz import Digraph"
      ],
      "metadata": {
        "id": "ZMGMW_qMzb41"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(data, target_col):\n",
        "    \"\"\"\n",
        "    Calculate entropy of the target column\n",
        "    \"\"\"\n",
        "    values = data[target_col].value_counts(normalize=True)\n",
        "    entropy = -sum(values * np.log2(values))\n",
        "    return round(entropy, 3)"
      ],
      "metadata": {
        "id": "oO_XyswrzkBw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_information_gain(data, feature_col, target_col):\n",
        "    \"\"\"\n",
        "    Calculate information gain of a feature\n",
        "    \"\"\"\n",
        "    total_entropy = calculate_entropy(data, target_col)\n",
        "    values = data[feature_col].unique()\n",
        "    weighted_entropy = 0\n",
        "\n",
        "    for value in values:\n",
        "        subset = data[data[feature_col] == value]\n",
        "        weight = len(subset) / len(data)\n",
        "        subset_entropy = calculate_entropy(subset, target_col)\n",
        "        weighted_entropy += weight * subset_entropy\n",
        "\n",
        "    info_gain = total_entropy - weighted_entropy\n",
        "    return round(info_gain, 3)"
      ],
      "metadata": {
        "id": "nIF1SPpLzlrG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_decision_tree(data, target_col, features, depth=0):\n",
        "    \"\"\"\n",
        "    Recursively build a decision tree using ID3 algorithm\n",
        "    \"\"\"\n",
        "    # Check if the dataset is homogeneous\n",
        "    if len(data[target_col].unique()) == 1:\n",
        "        return data[target_col].iloc[0]\n",
        "\n",
        "    # If no features left, return the most common class\n",
        "    if not features:\n",
        "        return data[target_col].mode()[0]\n",
        "\n",
        "    # Calculate information gain for each feature\n",
        "    gains = {feature: calculate_information_gain(data, feature, target_col) for feature in features}\n",
        "    best_feature = max(gains, key=gains.get)  # Choose the feature with the highest information gain\n",
        "\n",
        "    # Build the decision tree\n",
        "    tree = {best_feature: {}}\n",
        "\n",
        "    for value in data[best_feature].unique():\n",
        "        subset = data[data[best_feature] == value]\n",
        "        if subset.empty:\n",
        "            tree[best_feature][value] = data[target_col].mode()[0]\n",
        "        else:\n",
        "            subtree = build_decision_tree(\n",
        "                subset,\n",
        "                target_col,\n",
        "                [feat for feat in features if feat != best_feature],\n",
        "                depth + 1\n",
        "            )\n",
        "            tree[best_feature][value] = subtree\n",
        "\n",
        "    return tree"
      ],
      "metadata": {
        "id": "Ig1qKQZazn_F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rules(tree, path=\"\"):\n",
        "    \"\"\"\n",
        "    Convert a decision tree into rules\n",
        "    \"\"\"\n",
        "    if not isinstance(tree, dict):  # Leaf node\n",
        "        print(f\"{path} => {tree}\")\n",
        "        return\n",
        "\n",
        "    for node, branches in tree.items():\n",
        "        for value, subtree in branches.items():\n",
        "            new_path = f\"{path} {node} = {value}\" if path else f\"{node} = {value}\"\n",
        "            print_rules(subtree, new_path)"
      ],
      "metadata": {
        "id": "LTXqw2j4yqm4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_tree(tree, graph=None, parent=None, edge_label=\"\"):\n",
        "    \"\"\"\n",
        "    Visualize a decision tree using Graphviz\n",
        "    \"\"\"\n",
        "    if graph is None:\n",
        "        graph = Digraph(format='png')\n",
        "        graph.attr('node', shape='ellipse')\n",
        "\n",
        "    if isinstance(tree, dict):  # Decision node\n",
        "        for node, branches in tree.items():\n",
        "            graph.node(node, label=node)  # Add decision node\n",
        "            if parent:\n",
        "                graph.edge(parent, node, label=edge_label)\n",
        "            for branch_value, subtree in branches.items():\n",
        "                visualize_tree(subtree, graph, parent=node, edge_label=str(branch_value))\n",
        "    else:  # Leaf node\n",
        "        leaf_label = f\"{tree}\"  # Use leaf value as label\n",
        "        leaf_node = f\"{parent}_{leaf_label}\"  # Unique ID for leaf\n",
        "        graph.node(leaf_node, label=leaf_label, shape='box')\n",
        "        graph.edge(parent, leaf_node, label=edge_label)\n",
        "\n",
        "    return graph"
      ],
      "metadata": {
        "id": "ScRBy9IgzqPb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "file_path = input(\"Enter the path to your CSV file: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I8ejD5TzsH_",
        "outputId": "44676537-1d4c-4efc-8964-48a3d54ba73a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path to your CSV file: /content/ID3_Dataseti.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = input(\"Enter the target column name: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGpbSK9Xzu0x",
        "outputId": "adf0788e-8f21-468a-aac6-7007b17cceba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the target column name: Play\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "UD0TOdaTzwDr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (exclude target column)\n",
        "features = [col for col in data.columns if col != target_col]\n",
        "\n",
        "# Build the decision tree\n",
        "decision_tree = build_decision_tree(data, target_col, features)\n",
        "\n",
        "# Visualize the decision tree\n",
        "dot = visualize_tree(decision_tree)\n",
        "dot.render(\"decision_tree1\")  # Save the tree to a file\n",
        "print(\"Decision tree has been saved as decision_tree1.png\")\n",
        "print(\"Decision Tree Rules:\")\n",
        "print_rules(decision_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLaFL-iVz0ww",
        "outputId": "652cd23b-fa20-4843-af5e-ec68aba07358"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree has been saved as decision_tree1.png\n",
            "Decision Tree Rules:\n",
            "Outlook = rainy Humidity = high => no\n",
            "Outlook = rainy Humidity = normal => yes\n",
            "Outlook = overcast => yes\n",
            "Outlook = sunny Windy = False => yes\n",
            "Outlook = sunny Windy = True => no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Hali"
      ],
      "metadata": {
        "id": "2KYFe_aF2De7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from graphviz import Digraph\n",
        "\n",
        "def calculate_entropy(data, target_col):\n",
        "    \"\"\"\n",
        "    Calculate entropy of the target column\n",
        "    \"\"\"\n",
        "    values = data[target_col].value_counts(normalize=True)\n",
        "    entropy = -sum(values * np.log2(values))\n",
        "    return round(entropy, 3)\n",
        "\n",
        "def calculate_information_gain(data, feature_col, target_col):\n",
        "    \"\"\"\n",
        "    Calculate information gain of a feature\n",
        "    \"\"\"\n",
        "    total_entropy = calculate_entropy(data, target_col)\n",
        "    values = data[feature_col].unique()\n",
        "    weighted_entropy = 0\n",
        "\n",
        "    for value in values:\n",
        "        subset = data[data[feature_col] == value]\n",
        "        weight = len(subset) / len(data)\n",
        "        subset_entropy = calculate_entropy(subset, target_col)\n",
        "        weighted_entropy += weight * subset_entropy\n",
        "\n",
        "    info_gain = total_entropy - weighted_entropy\n",
        "    return round(info_gain, 3)\n",
        "\n",
        "def build_decision_tree(data, target_col, features, depth=0):\n",
        "    \"\"\"\n",
        "    Recursively build a decision tree using ID3 algorithm\n",
        "    \"\"\"\n",
        "    # Check if the dataset is homogeneous\n",
        "    if len(data[target_col].unique()) == 1:\n",
        "        return data[target_col].iloc[0]\n",
        "\n",
        "    # If no features left, return the most common class\n",
        "    if not features:\n",
        "        return data[target_col].mode()[0]\n",
        "\n",
        "    # Calculate information gain for each feature\n",
        "    gains = {feature: calculate_information_gain(data, feature, target_col) for feature in features}\n",
        "    best_feature = max(gains, key=gains.get)  # Choose the feature with the highest information gain\n",
        "\n",
        "    # Build the decision tree\n",
        "    tree = {best_feature: {}}\n",
        "\n",
        "    for value in data[best_feature].unique():\n",
        "        subset = data[data[best_feature] == value]\n",
        "        if subset.empty:\n",
        "            tree[best_feature][value] = data[target_col].mode()[0]\n",
        "        else:\n",
        "            subtree = build_decision_tree(\n",
        "                subset,\n",
        "                target_col,\n",
        "                [feat for feat in features if feat != best_feature],\n",
        "                depth + 1\n",
        "            )\n",
        "            tree[best_feature][value] = subtree\n",
        "\n",
        "    return tree\n",
        "\n",
        "def visualize_tree(tree, graph=None, parent=None, edge_label=\"\"):\n",
        "    \"\"\"\n",
        "    Visualize a decision tree using Graphviz\n",
        "    \"\"\"\n",
        "    if graph is None:\n",
        "        graph = Digraph(format='png')\n",
        "        graph.attr('node', shape='ellipse')\n",
        "\n",
        "    if isinstance(tree, dict):  # Decision node\n",
        "        for node, branches in tree.items():\n",
        "            graph.node(node, label=node)  # Add decision node\n",
        "            if parent:\n",
        "                graph.edge(parent, node, label=edge_label)\n",
        "            for branch_value, subtree in branches.items():\n",
        "                visualize_tree(subtree, graph, parent=node, edge_label=str(branch_value))\n",
        "    else:  # Leaf node\n",
        "        leaf_label = f\"{tree}\"  # Use leaf value as label\n",
        "        leaf_node = f\"{parent}_{leaf_label}\"  # Unique ID for leaf\n",
        "        graph.node(leaf_node, label=leaf_label, shape='box')\n",
        "        graph.edge(parent, leaf_node, label=edge_label)\n",
        "\n",
        "    return graph\n",
        "\n",
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset:\n",
        "    1. Drop numeric columns (warn user if any are found).\n",
        "    2. Check for missing values and handle them.\n",
        "    3. Verify target column and feature columns.\n",
        "    \"\"\"\n",
        "    # Detect numeric columns\n",
        "    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if numeric_columns:\n",
        "        print(f\"Warning: The dataset contains numeric columns: {numeric_columns}\")\n",
        "        print(\"These columns will be dropped.\")\n",
        "        data = data.drop(columns=numeric_columns)\n",
        "\n",
        "    # Handle missing values\n",
        "    if data.isnull().values.any():\n",
        "        print(\"Warning: Missing values detected in the dataset.\")\n",
        "        print(\"Filling missing values with the most frequent value in each column.\")\n",
        "        data = data.fillna(data.mode().iloc[0])\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load dataset\n",
        "file_path = input(\"Enter the path to your CSV file: \")\n",
        "target_col = input(\"Enter the target column name: \")\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the dataset\n",
        "data = preprocess_data(data)\n",
        "\n",
        "# Check if target column exists\n",
        "if target_col not in data.columns:\n",
        "    raise ValueError(f\"Target column '{target_col}' not found in the dataset.\")\n",
        "\n",
        "# Define features (exclude target column)\n",
        "features = [col for col in data.columns if col != target_col]\n",
        "\n",
        "# Build the decision tree\n",
        "decision_tree = build_decision_tree(data, target_col, features)\n",
        "\n",
        "# Visualize the decision tree\n",
        "dot = visualize_tree(decision_tree)\n",
        "dot.render(\"decision_tree1\")  # Save the tree to a file\n",
        "print(\"Decision tree has been saved as decision_tree1.png\")\n",
        "\n",
        "# Performance Metrics\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Number of features used: {len(features)}\")\n",
        "print(f\"Number of classes in target column: {data[target_col].nunique()}\")\n",
        "print(f\"Dataset size: {data.shape[0]} rows, {data.shape[1]} columns\")"
      ],
      "metadata": {
        "id": "dTBUqSWZ2Qjg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}